{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b98830b",
   "metadata": {},
   "source": [
    "# iteration2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e250ad4",
   "metadata": {},
   "source": [
    "Data:\n",
    "- interaktiot kaikkien muiden ryhmistä paitsi Alman kehittäjien\n",
    "- interaktiot ryhmä, ei käyttäjäkohtaisia\n",
    "- kaikki yritykset - konsernien tiedot pudotettu pois\n",
    "- metadatana perustietoa yrityksistä - numeeriset tilikausitiedot diskretisoitu tiettyihin persentiileihin (kts. muuttuja SELECTED_COMPANY_FEATURES alta)\n",
    "- **data esikäsitelty proto2_data_prep-notebookissa**\n",
    "\n",
    "Kysymyksiä:\n",
    "\n",
    "1. Saadaanko näillä lisätyillä metatiedoilla mallista parempi metatietojen kanssa kuin ilman?\n",
    "2. Saadaanko lisätyillä metatiedoilla parempi precision, recall ja reciprocal?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed64ea90",
   "metadata": {},
   "source": [
    "## Importit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff4d3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.evaluation import reciprocal_rank\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statistics\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed481a34",
   "metadata": {},
   "source": [
    "## Valitut metadatat yrityksille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b4c77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_COMPANY_FEATURES = ['company_form_code', 'location_municipality_code', \n",
    "                             'location_region_code', 'company_status_code', 'industry_code', 'turnover', \n",
    "                             'net_profit', 'personnel_average', 'performer_ranking_points', 'risk_rating_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d91921",
   "metadata": {},
   "source": [
    "## Ladataan yritysdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224730b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPANIES_DF = pd.read_pickle(\"../data/pandas_pickles/prod_data_proto2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3cfbfe",
   "metadata": {},
   "source": [
    "## Käsitellään yritysdataa LightFM:n Dataset-olion luontia varten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c27c6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('31431209', ['company_form_code+CO_26', 'location_municipality_code+091', 'location_region_code+01', 'company_status_code+AKT', 'industry_code+43', 'turnover+NaN', 'net_profit+NaN', 'personnel_average+NaN', 'performer_ranking_points+NaN', 'risk_rating_class+NaN'])\n",
      "1334601\n",
      "530\n"
     ]
    }
   ],
   "source": [
    "ITEM_IDS = list(COMPANIES_DF['business_id'].unique())\n",
    "\n",
    "item_features_tmp = [COMPANIES_DF[feature].unique() for feature in SELECTED_COMPANY_FEATURES]\n",
    "\n",
    "ITEM_FEATURE_LABELS = [item for sublist in item_features_tmp for item in sublist]\n",
    "\n",
    "ITEM_FEATURES = [(company['business_id'], \n",
    "                  [company[feature] for feature in SELECTED_COMPANY_FEATURES])\n",
    "                     for company in COMPANIES_DF.to_dict(orient='records')]\n",
    "\n",
    "print(ITEM_FEATURES[0])\n",
    "print(len(ITEM_FEATURES))\n",
    "print(len(ITEM_FEATURE_LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947fe51",
   "metadata": {},
   "source": [
    "## Ladataan vuorovaikutusdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e37e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_tmp = pd \\\n",
    "    .read_csv('../data/interactions_2021_08_19.csv',\n",
    "             delimiter='\\t',\n",
    "             dtype={\n",
    "                 'group_id': 'string',\n",
    "                 'business_id': 'string',\n",
    "                 'owner': 'string'\n",
    "             })\n",
    "\n",
    "# Poistetaan vuorovaikutusdatasta sellaiset y-tunnukset, joita ei löydy kohteista\n",
    "INTERACTIONS_DF = interactions_tmp[interactions_tmp.business_id.isin(ITEM_IDS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1e70b",
   "metadata": {},
   "source": [
    "## Luodaan vuorovaikutusdatasta versiot erilaisilla minimiryhmäko'oilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47d2e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sizes = INTERACTIONS_DF['group_id'].value_counts()\n",
    "group_sizes_df = pd.DataFrame({'group_id': group_sizes.index, 'group_size': group_sizes.values})\n",
    "\n",
    "INTERACTIONS_WITH_GROUP_SIZES_DF = INTERACTIONS_DF.merge(group_sizes_df, on='group_id')\n",
    "\n",
    "\n",
    "##### Minimiryhmäkoko = 10 #####\n",
    "\n",
    "INTERACTIONS_10_DF = INTERACTIONS_WITH_GROUP_SIZES_DF[INTERACTIONS_WITH_GROUP_SIZES_DF.group_size >= 10]\n",
    "\n",
    "\n",
    "##### Minimiryhmäkoko = 50\n",
    "\n",
    "INTERACTIONS_50_DF = INTERACTIONS_WITH_GROUP_SIZES_DF[INTERACTIONS_WITH_GROUP_SIZES_DF.group_size >= 50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a63d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- group_size>=1 -----\n",
      "ryhmiä: 1399, interaktioita 525513, yrityksiä 140677\n",
      "\n",
      "----- group_size>=10 -----\n",
      "ryhmiä: 1015, interaktioita 524053, yrityksiä 140604\n",
      "\n",
      "----- group_size>=50 -----\n",
      "ryhmiä: 722, interaktioita 517150, yrityksiä 140284\n"
     ]
    }
   ],
   "source": [
    "def print_interactions_meta_data(interactions_df):\n",
    "    print('ryhmiä: {groups}, interaktioita {interactions}, yrityksiä {companies}'\n",
    "          .format(groups=len(list(interactions_df['group_id'].unique())),\n",
    "                  interactions=interactions_df.shape[0], \n",
    "                  companies=len(list(interactions_df['business_id'].unique()))))\n",
    "\n",
    "print('----- group_size>=1 -----')\n",
    "print_interactions_meta_data(INTERACTIONS_DF)\n",
    "\n",
    "print('\\n----- group_size>=10 -----')\n",
    "print_interactions_meta_data(INTERACTIONS_10_DF)\n",
    "\n",
    "print('\\n----- group_size>=50 -----')\n",
    "print_interactions_meta_data(INTERACTIONS_50_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec70bcb",
   "metadata": {},
   "source": [
    "## Luodaan LightFM:n ymmärtämät Dataset-oliot eri ryhmäko'oille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61d09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(interactions_df):\n",
    "    dataset = Dataset(user_identity_features=False, item_identity_features=False)\n",
    "    \n",
    "    interactions = [(interaction['group_id'], interaction['business_id']) \n",
    "                for interaction in interactions_df.to_dict(orient='records')]\n",
    "    \n",
    "    user_ids = list(set(interactions_df['group_id'].values))\n",
    "\n",
    "    dataset.fit(users=user_ids, items=ITEM_IDS, item_features=ITEM_FEATURE_LABELS)\n",
    "    \n",
    "    (interactions_ds, weights_ds) = dataset.build_interactions(interactions)\n",
    "    \n",
    "    item_features_ds = dataset.build_item_features(ITEM_FEATURES, normalize=False)\n",
    "\n",
    "    # USER_MAP_DS = dataset.mapping()[0]\n",
    "    # ITEM_MAP_DS = dataset.mapping()[2]\n",
    "    # ITEM_FEATURE_MAP_DS = dataset.mapping()[3]\n",
    "    \n",
    "    return (interactions_ds, item_features_ds)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c34f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<1399x1334601 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 525513 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "(INTERACTIONS_DS, ITEM_FEATURES_DS) = create_dataset(INTERACTIONS_DF)\n",
    "print(repr(INTERACTIONS_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d6abd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<1015x1334601 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 524053 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "(INTERACTIONS_10_DS, ITEM_FEATURES_10_DS) = create_dataset(INTERACTIONS_10_DF)\n",
    "print(repr(INTERACTIONS_10_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ea02e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<722x1334601 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 517150 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "(INTERACTIONS_50_DS, ITEM_FEATURES_50_DS) = create_dataset(INTERACTIONS_50_DF)\n",
    "print(repr(INTERACTIONS_50_DS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf4bd3",
   "metadata": {},
   "source": [
    "## Luodaan cross-validationia varten ositetut datasetit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edcd7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partitioned_datasets(interactions_ds):\n",
    "    (half_1, half_2) = random_train_test_split(interactions_ds, test_percentage=0.5)\n",
    "    (quarter_1, quarter_2) = random_train_test_split(half_1, test_percentage=0.5)\n",
    "    (quarter_3, quarter_4) = random_train_test_split(half_2, test_percentage=0.5)\n",
    "    \n",
    "    return [quarter_1, quarter_2, quarter_3, quarter_4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df8419e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERACTIONS_CV = create_partitioned_datasets(INTERACTIONS_DS)\n",
    "INTERACTIONS_10_CV = create_partitioned_datasets(INTERACTIONS_10_DS)\n",
    "INTERACTIONS_50_CV = create_partitioned_datasets(INTERACTIONS_50_DS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91a64d",
   "metadata": {},
   "source": [
    "## Arvioidaan mallien laatua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f98c56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_function(model, test_ds, train_ds, evaluation_function, name, item_features=None):    \n",
    "    print('Calculating {name} for train dataset...'.format(name=name))\n",
    "    train_metric = evaluation_function(model, train_ds, item_features=item_features, num_threads=6).mean()\n",
    "    \n",
    "    print('Calculating {name} for test dataset...'.format(name=name))\n",
    "    test_metric = evaluation_function(model, test_ds, item_features=item_features, num_threads=6).mean()\n",
    "    \n",
    "    print('{name}: train {train_metric:.2f}, test {test_metric:.2f}'.format(name=name, \n",
    "                                                                            train_metric=train_metric, \n",
    "                                                                            test_metric=test_metric))\n",
    "    print(\"\\n\")\n",
    "    return (train_metric, test_metric)\n",
    "\n",
    "\n",
    "def run_evaluations_for_ds(model, train_ds, test_ds, model_name=None, item_features=None):\n",
    "    auc = run_evaluation_function(model, test_ds, train_ds, auc_score, 'AUC_' + model_name, item_features)\n",
    "    precision = run_evaluation_function(model, test_ds, train_ds, precision_at_k, 'PRECISION_' + model_name, item_features)\n",
    "    recall = run_evaluation_function(model, test_ds, train_ds, recall_at_k, 'RECALL_' + model_name, item_features)\n",
    "    reciprocal = run_evaluation_function(model, test_ds, train_ds, reciprocal_rank, 'RECIPROCAL_' + model_name, item_features)\n",
    "    \n",
    "    return (auc, precision, recall, reciprocal)\n",
    "    \n",
    "\n",
    "def run_evaluations(interactions_cv, item_features_ds, model_epochs):\n",
    "    \n",
    "    results = {\n",
    "        'WARP': [],\n",
    "        'BPR': [],\n",
    "        'WARP_NO_ITEM': [],\n",
    "        'BPR_NO_ITEM': []\n",
    "    }\n",
    "    \n",
    "    for i in range(0, len(interactions_cv)):\n",
    "        print('Starting iteration {}...'.format(i))\n",
    "        \n",
    "        test_ds = interactions_cv[i]\n",
    "        \n",
    "        # laitetaan uuteen listaan kaikki paitsi testidatasetti\n",
    "        train_ds_tmp = [ds for j,ds in enumerate(interactions_cv) if j != i]\n",
    "        # yhdistetään treenidatasetiksi valikoituneet vuorovaikutusmatriisit\n",
    "        train_ds = functools.reduce(lambda a,b: a + b, train_ds_tmp)\n",
    "        \n",
    "        MODEL_WARP = LightFM(loss='warp')\n",
    "        MODEL_WARP.fit(train_ds, item_features=item_features_ds, epochs=model_epochs, num_threads=6, verbose=True)\n",
    "\n",
    "        MODEL_BPR = LightFM(loss='bpr')\n",
    "        MODEL_BPR.fit(train_ds, item_features=item_features_ds, epochs=model_epochs, num_threads=6, verbose=True)\n",
    "\n",
    "        MODEL_WARP_NO_ITEM = LightFM(loss='warp')\n",
    "        MODEL_WARP_NO_ITEM.fit(train_ds, epochs=model_epochs, num_threads=4, verbose=True)\n",
    "\n",
    "        MODEL_BPR_NO_ITEM = LightFM(loss='bpr')\n",
    "        MODEL_BPR_NO_ITEM.fit(train_ds, epochs=model_epochs, num_threads=4, verbose=True)\n",
    "        \n",
    "        results['WARP'].append(run_evaluations_for_ds(MODEL_WARP, train_ds, test_ds, 'WARP', item_features_ds))\n",
    "        results['BPR'].append(run_evaluations_for_ds(MODEL_BPR, train_ds, test_ds, 'BPR', item_features_ds))\n",
    "        results['WARP_NO_ITEM'].append(run_evaluations_for_ds(MODEL_WARP_NO_ITEM, train_ds, test_ds, 'WARP_NO_ITEM'))\n",
    "        results['BPR_NO_ITEM'].append(run_evaluations_for_ds(MODEL_BPR_NO_ITEM, train_ds, test_ds, 'BPR_NO_ITEM'))\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07240adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_simple_results(results_tuple):\n",
    "    auc, precision, recall, reciprocal = results_tuple\n",
    "    print('AUC: \\n train {} \\n test {}'.format(auc[0], auc[1]))\n",
    "    print('PRECISION: \\n train {} \\n test {}'.format(precision[0], precision[1]))\n",
    "    print('RECALL: \\n train {} \\n test {}'.format(recall[0], recall[1]))\n",
    "    print('RECIPROCAL: \\n train {} \\n test {}'.format(reciprocal[0], reciprocal[1]))    \n",
    "    \n",
    "\n",
    "def print_metric_result(result_arr, model_name):\n",
    "    train_results = [x[0] for x in result_arr]\n",
    "    test_results = [x[1] for x in result_arr]\n",
    "    \n",
    "    print('{name}:\\n train mean {train_mean:.2f} ({train_arr})\\n test mean {test_mean:.2f} ({test_arr})\\n'\n",
    "          .format(train_mean=statistics.mean(train_results),\n",
    "                 test_mean=statistics.mean(test_results),\n",
    "                 train_arr=['%.2f' % x for x in train_results],\n",
    "                 test_arr=['%.2f' % x for x in test_results],\n",
    "                 name=model_name))\n",
    "    \n",
    "\n",
    "def print_all_results(results):\n",
    "    for i,metric in enumerate(['AUC', 'PRECISION', 'RECALL', 'RECIPROCAL']):\n",
    "        print('\\n-----{}-----'.format(metric))\n",
    "        for model_name,result_arr in results.items():\n",
    "            print_metric_result([res[i] for res in result_arr], model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1637f48",
   "metadata": {},
   "source": [
    "### group_size >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095d0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:01<00:00,  3.06it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:01<00:00,  3.93it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:02<00:00,  2.35it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:00<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC_WARP for train dataset...\n",
      "Calculating AUC_WARP for test dataset...\n"
     ]
    }
   ],
   "source": [
    "RESULTS_1 = run_evaluations(INTERACTIONS_CV, ITEM_FEATURES_DS, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dbea4d",
   "metadata": {},
   "source": [
    "### group_size >= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc023578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:05<00:00,  1.00s/it]\n",
      "Epoch: 100%|██████████| 5/5 [00:02<00:00,  1.97it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
      "Epoch: 100%|██████████| 5/5 [00:03<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC_WARP for train dataset...\n",
      "Calculating AUC_WARP for test dataset...\n",
      "AUC_WARP: train 0.97, test 0.97\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP for train dataset...\n",
      "Calculating PRECISION_WARP for test dataset...\n",
      "PRECISION_WARP: train 0.02, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP for train dataset...\n",
      "Calculating RECALL_WARP for test dataset...\n",
      "RECALL_WARP: train 0.00, test 0.00\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP for train dataset...\n",
      "Calculating RECIPROCAL_WARP for test dataset...\n",
      "RECIPROCAL_WARP: train 0.07, test 0.03\n",
      "\n",
      "\n",
      "Calculating AUC_BPR for train dataset...\n",
      "Calculating AUC_BPR for test dataset...\n",
      "AUC_BPR: train 0.94, test 0.93\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR for train dataset...\n",
      "Calculating PRECISION_BPR for test dataset...\n",
      "PRECISION_BPR: train 0.01, test 0.00\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR for train dataset...\n",
      "Calculating RECALL_BPR for test dataset...\n",
      "RECALL_BPR: train 0.00, test 0.00\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_BPR for train dataset...\n",
      "Calculating RECIPROCAL_BPR for test dataset...\n",
      "RECIPROCAL_BPR: train 0.04, test 0.02\n",
      "\n",
      "\n",
      "Calculating AUC_WARP_NO_ITEM for train dataset...\n",
      "Calculating AUC_WARP_NO_ITEM for test dataset...\n",
      "AUC_WARP_NO_ITEM: train 0.99, test 0.94\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_WARP_NO_ITEM for test dataset...\n",
      "PRECISION_WARP_NO_ITEM: train 0.19, test 0.05\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECALL_WARP_NO_ITEM for test dataset...\n",
      "RECALL_WARP_NO_ITEM: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for test dataset...\n",
      "RECIPROCAL_WARP_NO_ITEM: train 0.31, test 0.12\n",
      "\n",
      "\n",
      "Calculating AUC_BPR_NO_ITEM for train dataset...\n",
      "Calculating AUC_BPR_NO_ITEM for test dataset...\n",
      "AUC_BPR_NO_ITEM: train 0.85, test 0.81\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_BPR_NO_ITEM for test dataset...\n",
      "PRECISION_BPR_NO_ITEM: train 0.18, test 0.04\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR_NO_ITEM for train dataset...\n"
     ]
    }
   ],
   "source": [
    "RESULTS_10 = run_evaluations(INTERACTIONS_10_CV, ITEM_FEATURES_10_DS, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7373a50",
   "metadata": {},
   "source": [
    "### group_size >= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f33c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:02<00:00,  2.13it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:04<00:00,  1.14it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:02<00:00,  1.71it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:01<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC_WARP for train dataset...\n",
      "Calculating AUC_WARP for test dataset...\n",
      "AUC_WARP: train 0.99, test 0.99\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP for train dataset...\n",
      "Calculating PRECISION_WARP for test dataset...\n",
      "PRECISION_WARP: train 0.22, test 0.07\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP for train dataset...\n",
      "Calculating RECALL_WARP for test dataset...\n",
      "RECALL_WARP: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP for train dataset...\n",
      "Calculating RECIPROCAL_WARP for test dataset...\n",
      "RECIPROCAL_WARP: train 0.36, test 0.17\n",
      "\n",
      "\n",
      "Calculating AUC_BPR for train dataset...\n",
      "Calculating AUC_BPR for test dataset...\n",
      "AUC_BPR: train 0.96, test 0.96\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR for train dataset...\n",
      "Calculating PRECISION_BPR for test dataset...\n",
      "PRECISION_BPR: train 0.23, test 0.07\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR for train dataset...\n",
      "Calculating RECALL_BPR for test dataset...\n",
      "RECALL_BPR: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_BPR for train dataset...\n",
      "Calculating RECIPROCAL_BPR for test dataset...\n",
      "RECIPROCAL_BPR: train 0.37, test 0.17\n",
      "\n",
      "\n",
      "Calculating AUC_WARP_NO_ITEM for train dataset...\n",
      "Calculating AUC_WARP_NO_ITEM for test dataset...\n",
      "AUC_WARP_NO_ITEM: train 0.99, test 0.94\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_WARP_NO_ITEM for test dataset...\n",
      "PRECISION_WARP_NO_ITEM: train 0.24, test 0.06\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECALL_WARP_NO_ITEM for test dataset...\n",
      "RECALL_WARP_NO_ITEM: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for test dataset...\n",
      "RECIPROCAL_WARP_NO_ITEM: train 0.35, test 0.14\n",
      "\n",
      "\n",
      "Calculating AUC_BPR_NO_ITEM for train dataset...\n",
      "Calculating AUC_BPR_NO_ITEM for test dataset...\n",
      "AUC_BPR_NO_ITEM: train 0.86, test 0.82\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_BPR_NO_ITEM for test dataset...\n",
      "PRECISION_BPR_NO_ITEM: train 0.23, test 0.05\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR_NO_ITEM for train dataset...\n",
      "Calculating RECALL_BPR_NO_ITEM for test dataset...\n",
      "RECALL_BPR_NO_ITEM: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_BPR_NO_ITEM for train dataset...\n",
      "Calculating RECIPROCAL_BPR_NO_ITEM for test dataset...\n",
      "RECIPROCAL_BPR_NO_ITEM: train 0.32, test 0.12\n",
      "\n",
      "\n",
      "Starting iteration 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:02<00:00,  2.42it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:01<00:00,  2.86it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:00<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC_WARP for train dataset...\n",
      "Calculating AUC_WARP for test dataset...\n",
      "AUC_WARP: train 0.99, test 0.99\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP for train dataset...\n",
      "Calculating PRECISION_WARP for test dataset...\n",
      "PRECISION_WARP: train 0.20, test 0.07\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP for train dataset...\n",
      "Calculating RECALL_WARP for test dataset...\n",
      "RECALL_WARP: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP for train dataset...\n",
      "Calculating RECIPROCAL_WARP for test dataset...\n",
      "RECIPROCAL_WARP: train 0.34, test 0.18\n",
      "\n",
      "\n",
      "Calculating AUC_BPR for train dataset...\n",
      "Calculating AUC_BPR for test dataset...\n",
      "AUC_BPR: train 0.96, test 0.96\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR for train dataset...\n",
      "Calculating PRECISION_BPR for test dataset...\n",
      "PRECISION_BPR: train 0.23, test 0.08\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR for train dataset...\n",
      "Calculating RECALL_BPR for test dataset...\n",
      "RECALL_BPR: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_BPR for train dataset...\n",
      "Calculating RECIPROCAL_BPR for test dataset...\n",
      "RECIPROCAL_BPR: train 0.38, test 0.21\n",
      "\n",
      "\n",
      "Calculating AUC_WARP_NO_ITEM for train dataset...\n",
      "Calculating AUC_WARP_NO_ITEM for test dataset...\n",
      "AUC_WARP_NO_ITEM: train 0.99, test 0.94\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_WARP_NO_ITEM for test dataset...\n",
      "PRECISION_WARP_NO_ITEM: train 0.23, test 0.05\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECALL_WARP_NO_ITEM for test dataset...\n",
      "RECALL_WARP_NO_ITEM: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for test dataset...\n",
      "RECIPROCAL_WARP_NO_ITEM: train 0.37, test 0.13\n",
      "\n",
      "\n",
      "Calculating AUC_BPR_NO_ITEM for train dataset...\n",
      "Calculating AUC_BPR_NO_ITEM for test dataset...\n",
      "AUC_BPR_NO_ITEM: train 0.87, test 0.82\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_BPR_NO_ITEM for test dataset...\n",
      "PRECISION_BPR_NO_ITEM: train 0.24, test 0.05\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR_NO_ITEM for train dataset...\n",
      "Calculating RECALL_BPR_NO_ITEM for test dataset...\n",
      "RECALL_BPR_NO_ITEM: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_BPR_NO_ITEM for train dataset...\n",
      "Calculating RECIPROCAL_BPR_NO_ITEM for test dataset...\n",
      "RECIPROCAL_BPR_NO_ITEM: train 0.35, test 0.12\n",
      "\n",
      "\n",
      "Starting iteration 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:02<00:00,  2.36it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:04<00:00,  1.11it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:01<00:00,  2.80it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:00<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC_WARP for train dataset...\n",
      "Calculating AUC_WARP for test dataset...\n",
      "AUC_WARP: train 0.99, test 0.99\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP for train dataset...\n",
      "Calculating PRECISION_WARP for test dataset...\n",
      "PRECISION_WARP: train 0.22, test 0.07\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP for train dataset...\n",
      "Calculating RECALL_WARP for test dataset...\n",
      "RECALL_WARP: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP for train dataset...\n",
      "Calculating RECIPROCAL_WARP for test dataset...\n",
      "RECIPROCAL_WARP: train 0.35, test 0.18\n",
      "\n",
      "\n",
      "Calculating AUC_BPR for train dataset...\n",
      "Calculating AUC_BPR for test dataset...\n",
      "AUC_BPR: train 0.96, test 0.96\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR for train dataset...\n",
      "Calculating PRECISION_BPR for test dataset...\n",
      "PRECISION_BPR: train 0.21, test 0.07\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR for train dataset...\n",
      "Calculating RECALL_BPR for test dataset...\n",
      "RECALL_BPR: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_BPR for train dataset...\n",
      "Calculating RECIPROCAL_BPR for test dataset...\n",
      "RECIPROCAL_BPR: train 0.33, test 0.16\n",
      "\n",
      "\n",
      "Calculating AUC_WARP_NO_ITEM for train dataset...\n",
      "Calculating AUC_WARP_NO_ITEM for test dataset...\n",
      "AUC_WARP_NO_ITEM: train 0.99, test 0.94\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_WARP_NO_ITEM for test dataset...\n",
      "PRECISION_WARP_NO_ITEM: train 0.25, test 0.06\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECALL_WARP_NO_ITEM for test dataset...\n",
      "RECALL_WARP_NO_ITEM: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for test dataset...\n",
      "RECIPROCAL_WARP_NO_ITEM: train 0.39, test 0.14\n",
      "\n",
      "\n",
      "Calculating AUC_BPR_NO_ITEM for train dataset...\n",
      "Calculating AUC_BPR_NO_ITEM for test dataset...\n",
      "AUC_BPR_NO_ITEM: train 0.86, test 0.82\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_BPR_NO_ITEM for test dataset...\n",
      "PRECISION_BPR_NO_ITEM: train 0.25, test 0.05\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR_NO_ITEM for train dataset...\n",
      "Calculating RECALL_BPR_NO_ITEM for test dataset...\n",
      "RECALL_BPR_NO_ITEM: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_BPR_NO_ITEM for train dataset...\n",
      "Calculating RECIPROCAL_BPR_NO_ITEM for test dataset...\n",
      "RECIPROCAL_BPR_NO_ITEM: train 0.36, test 0.13\n",
      "\n",
      "\n",
      "Starting iteration 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:02<00:00,  2.43it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:04<00:00,  1.16it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:01<00:00,  2.85it/s]\n",
      "Epoch: 100%|██████████| 5/5 [00:00<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating AUC_WARP for train dataset...\n",
      "Calculating AUC_WARP for test dataset...\n",
      "AUC_WARP: train 0.99, test 0.99\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP for train dataset...\n",
      "Calculating PRECISION_WARP for test dataset...\n",
      "PRECISION_WARP: train 0.20, test 0.07\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP for train dataset...\n",
      "Calculating RECALL_WARP for test dataset...\n",
      "RECALL_WARP: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP for train dataset...\n",
      "Calculating RECIPROCAL_WARP for test dataset...\n",
      "RECIPROCAL_WARP: train 0.33, test 0.17\n",
      "\n",
      "\n",
      "Calculating AUC_BPR for train dataset...\n",
      "Calculating AUC_BPR for test dataset...\n",
      "AUC_BPR: train 0.96, test 0.96\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR for train dataset...\n",
      "Calculating PRECISION_BPR for test dataset...\n",
      "PRECISION_BPR: train 0.22, test 0.07\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR for train dataset...\n",
      "Calculating RECALL_BPR for test dataset...\n",
      "RECALL_BPR: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_BPR for train dataset...\n",
      "Calculating RECIPROCAL_BPR for test dataset...\n",
      "RECIPROCAL_BPR: train 0.34, test 0.17\n",
      "\n",
      "\n",
      "Calculating AUC_WARP_NO_ITEM for train dataset...\n",
      "Calculating AUC_WARP_NO_ITEM for test dataset...\n",
      "AUC_WARP_NO_ITEM: train 0.99, test 0.93\n",
      "\n",
      "\n",
      "Calculating PRECISION_WARP_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_WARP_NO_ITEM for test dataset...\n",
      "PRECISION_WARP_NO_ITEM: train 0.25, test 0.06\n",
      "\n",
      "\n",
      "Calculating RECALL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECALL_WARP_NO_ITEM for test dataset...\n",
      "RECALL_WARP_NO_ITEM: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for train dataset...\n",
      "Calculating RECIPROCAL_WARP_NO_ITEM for test dataset...\n",
      "RECIPROCAL_WARP_NO_ITEM: train 0.40, test 0.14\n",
      "\n",
      "\n",
      "Calculating AUC_BPR_NO_ITEM for train dataset...\n",
      "Calculating AUC_BPR_NO_ITEM for test dataset...\n",
      "AUC_BPR_NO_ITEM: train 0.86, test 0.82\n",
      "\n",
      "\n",
      "Calculating PRECISION_BPR_NO_ITEM for train dataset...\n",
      "Calculating PRECISION_BPR_NO_ITEM for test dataset...\n",
      "PRECISION_BPR_NO_ITEM: train 0.22, test 0.05\n",
      "\n",
      "\n",
      "Calculating RECALL_BPR_NO_ITEM for train dataset...\n",
      "Calculating RECALL_BPR_NO_ITEM for test dataset...\n",
      "RECALL_BPR_NO_ITEM: train 0.01, test 0.01\n",
      "\n",
      "\n",
      "Calculating RECIPROCAL_BPR_NO_ITEM for train dataset...\n",
      "Calculating RECIPROCAL_BPR_NO_ITEM for test dataset...\n",
      "RECIPROCAL_BPR_NO_ITEM: train 0.32, test 0.12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RESULTS_50 = run_evaluations(INTERACTIONS_50_CV, ITEM_FEATURES_50_DS, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "221d44b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----AUC-----\n",
      "WARP:\n",
      " train mean 0.99 (['0.99', '0.99', '0.99', '0.99'])\n",
      " test mean 0.99 (['0.99', '0.99', '0.99', '0.99'])\n",
      "\n",
      "BPR:\n",
      " train mean 0.96 (['0.96', '0.96', '0.96', '0.96'])\n",
      " test mean 0.96 (['0.96', '0.96', '0.96', '0.96'])\n",
      "\n",
      "WARP_NO_ITEM:\n",
      " train mean 0.99 (['0.99', '0.99', '0.99', '0.99'])\n",
      " test mean 0.94 (['0.94', '0.94', '0.94', '0.93'])\n",
      "\n",
      "BPR_NO_ITEM:\n",
      " train mean 0.86 (['0.86', '0.87', '0.86', '0.86'])\n",
      " test mean 0.82 (['0.82', '0.82', '0.82', '0.82'])\n",
      "\n",
      "\n",
      "-----PRECISION-----\n",
      "WARP:\n",
      " train mean 0.21 (['0.22', '0.20', '0.22', '0.20'])\n",
      " test mean 0.07 (['0.07', '0.07', '0.07', '0.07'])\n",
      "\n",
      "BPR:\n",
      " train mean 0.22 (['0.23', '0.23', '0.21', '0.22'])\n",
      " test mean 0.07 (['0.07', '0.08', '0.07', '0.07'])\n",
      "\n",
      "WARP_NO_ITEM:\n",
      " train mean 0.24 (['0.24', '0.23', '0.25', '0.25'])\n",
      " test mean 0.06 (['0.06', '0.05', '0.06', '0.06'])\n",
      "\n",
      "BPR_NO_ITEM:\n",
      " train mean 0.24 (['0.23', '0.24', '0.25', '0.22'])\n",
      " test mean 0.05 (['0.05', '0.05', '0.05', '0.05'])\n",
      "\n",
      "\n",
      "-----RECALL-----\n",
      "WARP:\n",
      " train mean 0.01 (['0.01', '0.01', '0.01', '0.01'])\n",
      " test mean 0.01 (['0.01', '0.01', '0.01', '0.01'])\n",
      "\n",
      "BPR:\n",
      " train mean 0.01 (['0.01', '0.01', '0.01', '0.01'])\n",
      " test mean 0.01 (['0.01', '0.01', '0.01', '0.01'])\n",
      "\n",
      "WARP_NO_ITEM:\n",
      " train mean 0.01 (['0.01', '0.01', '0.01', '0.01'])\n",
      " test mean 0.01 (['0.01', '0.01', '0.01', '0.01'])\n",
      "\n",
      "BPR_NO_ITEM:\n",
      " train mean 0.01 (['0.01', '0.01', '0.01', '0.01'])\n",
      " test mean 0.01 (['0.01', '0.01', '0.01', '0.01'])\n",
      "\n",
      "\n",
      "-----RECIPROCAL-----\n",
      "WARP:\n",
      " train mean 0.35 (['0.36', '0.34', '0.35', '0.33'])\n",
      " test mean 0.17 (['0.17', '0.18', '0.18', '0.17'])\n",
      "\n",
      "BPR:\n",
      " train mean 0.35 (['0.37', '0.38', '0.33', '0.34'])\n",
      " test mean 0.18 (['0.17', '0.21', '0.16', '0.17'])\n",
      "\n",
      "WARP_NO_ITEM:\n",
      " train mean 0.38 (['0.35', '0.37', '0.39', '0.40'])\n",
      " test mean 0.14 (['0.14', '0.13', '0.14', '0.14'])\n",
      "\n",
      "BPR_NO_ITEM:\n",
      " train mean 0.34 (['0.32', '0.35', '0.36', '0.32'])\n",
      " test mean 0.12 (['0.12', '0.12', '0.13', '0.12'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_all_results(RESULTS_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC:een voisi koittaa visualisoida: kaikki scoret järjestykseen ja highlightaa osumat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
